# Introduction
The integration of learning and reasoning is a long-standing challenge in Artificial Intelligence (AI) [1]. Neurosymbolic AI, a subfield of AI that combines logical and neural representations, has emerged as a promising approach to address this challenge [2]. However, despite its growing popularity, neurosymbolic AI lacks a universally accepted definition, leading to confusion and fragmentation in the research community [3]. This paper aims to address this gap by proposing a formal definition of neurosymbolic AI and exploring its applications in scientific reasoning and automated writing.

In recent years, there has been a surge of interest in neurosymbolic AI, driven by its potential to combine the strengths of neural networks and symbolic systems [4]. This integration enables the representation and reasoning about complex logical formulas, which is essential for many real-world applications, such as scientific discovery, automated writing, and decision-making under uncertainty. However, the development of neurosymbolic AI systems is hindered by several challenges, including data efficiency, fairness, and safety.

To address these challenges, we propose a neurosymbolic AI system that can represent and reason formally about any propositional logic formula, combining learning from data and knowledge with logical reasoning [5]. We also conduct a literature survey of neurosymbolic reinforcement learning, categorizing works into three taxonomies and analyzing the RL components of each research work to identify research opportunities and challenges.

Furthermore, we introduce relational neurosymbolic Markov models, a new class of end-to-end differentiable sequential models that integrate and provably satisfy relational logical constraints [6]. These models can solve problems beyond the current state-of-the-art in neurosymbolic AI and provide strong guarantees with respect to desired properties, while also being more interpretable and adaptable to out-of-distribution scenarios.

In addition, we develop a unified formalism for probabilistic reasoning problems and create a complexity map to assess the scalability of neurosymbolic techniques, helping practitioners navigate the scalability landscape [7]. We also present Scallop, a language that combines deep learning and logical reasoning, enabling users to write and train neurosymbolic applications efficiently.

This paper contributes to the development of neurosymbolic AI by proposing a formal definition, exploring its applications in scientific reasoning and automated writing, and introducing new models and techniques that can solve complex problems [8]. Our work has the potential to promote the principled integration of reasoning and learning in deep networks, enabling the development of more accurate, efficient, and interpretable AI systems. [9]